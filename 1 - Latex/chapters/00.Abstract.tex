\documentclass[../main.tex]{subfiles}
\begin{document}
\begin{abstract}
This feasibility study explores automating administrative regularity controls in Italian municipalities using Large Language Models (LLMs). We evaluated a system where LLMs select and complete compliance checklists for administrative acts, comparing its performance against human expert evaluations. Using various LLMs (including GPT-4o series, Llama 3 series, and Mistral-7B, with 70B models 4-bit quantized) and specifically engineered prompts, the system achieved approximately 80\% accuracy and 70\% balanced accuracy, significantly speeding up the process compared to manual review. While results show LLMs are a promising tool for increasing efficiency and consistency, limitations in handling legal nuances necessitate continued human oversight. The findings support the potential of LLMs as assistive tools within a human-in-the-loop framework for public administration compliance tasks.

%% This is too long for an abstract
%Administrative regularity control is a critical compliance function in public administration, particularly within Italian municipalities, ensuring that administrative acts adhere to legal and procedural standards. However, traditional manual verification processes are resource-intensive, time-consuming, and susceptible to inconsistencies. This thesis presents a feasibility study investigating the application of Large Language Models (LLMs) to automate these control processes. We propose and evaluate a system employing LLMs, structured around two core tasks: autonomously selecting the appropriate domain-specific checklist for a given administrative act based on its content and predefined checklist descriptions, and subsequently evaluating the act against each point of the selected checklist. Our methodology involves processing official administrative acts (\textit{determine}) from Italian municipalities (Lucca and Olbia), utilizing structured checklists encoded in JSON format, and designing specific prompts to guide LLM behavior. We experiment with various LLMs, including OpenAI's GPT-4o series and open-weight models like Meta's Llama 3.1/3.2/3.3 (3B/8B/70B) and Mistral-7B, employing 4-bit quantization for larger models to manage computational resources. LLM-generated evaluations are standardized using regular expressions and compared against a ground truth established by a human expert in administrative control. Performance is assessed using metrics including accuracy, balanced accuracy, precision, recall, F1-score, and confusion matrices, while also analysing the impact of model parameters like temperature. Our findings indicate promising feasibility, with the automated system achieving approximately 80\% accuracy and 70\% balanced accuracy compared to human evaluation, alongside a significant reduction in processing time (approx. 2 minutes per act via LLM vs. 15-30 minutes manually). The models demonstrated a tendency towards cautiousness, often flagging potentially compliant items for review, and lower temperature settings generally yielded more consistent outputs. Despite the potential for enhanced efficiency and consistency, challenges remain, particularly in handling complex legal terminology and nuances where human expertise is still essential. While not yet a complete replacement for human auditors, the study concludes that LLM-based systems offer a viable tool to support and streamline administrative regularity controls, advocating for a human-in-the-loop approach in practical deployment within public administration.
\end{abstract}

% Include bibliography only when compiling this subfile independently
\ifSubfilesClassLoaded{
    \bibliographystyle{sapthesis}
    \bibliography{Tesi}
}{}

\end{document}

