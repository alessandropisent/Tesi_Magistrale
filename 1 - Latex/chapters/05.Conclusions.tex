\documentclass[../main.tex]{subfiles}
\begin{document}

\section{Key Findings}
Our experimental results indicate that the automated system achieves an accuracy of approximately 80\% and a balanced accuracy of around 70\% when compared with human evaluations. This demonstrates that, while the LLM-based approach is feasible, human oversight remains essential. Notably, the LLM did not perform as exceptionally as initially hypothesized for a simple question-answering task. We observed that the model's accuracy might be enhanced by incorporating more contextual information about the act, especially in cases involving significant monetary values, where stricter adherence to checklist criteria is imperative. Furthermore, our evaluation revealed that the automated process is considerably faster: while human review of each act takes between 15 to 30 minutes, the LLM completes the evaluation in approximately 2 minutes per act. An important aspect of our findings is that the model tends to err on the side of caution by classifying acts as non-compliant even when they might pass the check. This conservative approach is advantageous, as it ensures that any potential irregularity is flagged for human review rather than mistakenly approving an act.

\section{Feasibility and Effectiveness}
Our tests have confirmed the feasibility of utilizing LLMs in the domain of administrative regularity control. By conducting a thorough hyperparameter search, particularly focusing on the temperature setting, we found that lower temperature values generally result in more consistent and reliable outputs. Although the current accuracy is promising, it still falls short of replacing human evaluators entirely. Future work will be directed toward enhancing the model's performance, potentially by integrating additional context and refining the prompt engineering strategy. The promising speed and reasonable accuracy suggest that with further improvements, the system could effectively support administrative audits.

\section{Advantages and Limitations}
The primary advantage of our automated approach is the significant reduction in the time and human resources required for administrative audits. With the LLM handling the initial screening, the process becomes considerably more efficient, which could alleviate the workload on municipal staff. However, several limitations were also identified:
\begin{itemize}
    \item \textbf{Complex Legal Terminology:} The specialized legal language and synonymous terms in administrative acts present challenges for the LLM. There are instances where a human expert might recognize that two terms are synonymous, whereas the model may not.
    \item \textbf{Acronyms and Abbreviations:} Administrative documents often contain acronyms that are not well-defined within the text, which can confuse the model and impact its ability to accurately interpret the act.
\end{itemize}
These limitations underscore the need for further development and integration of domain-specific knowledge into the model.

\section{Implications for Municipalities}
The integration of an LLM-based auditing system in municipal administrations could have significant positive implications. If further refined, such a system can reduce the administrative burden, speed up the evaluation process, and enhance the overall transparency and accountability of public administration. By ensuring that even minor irregularities are flagged for further review, municipalities can maintain high standards of regulatory compliance. However, it is crucial to retain a human-in-the-loop framework to verify and interpret the model's outputs, especially given the current limitations in handling nuanced legal language.

\section{Scalability Considerations}
While our methodology has proven effective on a smaller scale, its scalability to other municipalities and contexts requires careful consideration. The approach can be adapted to different types of administrative documents, provided that the documents are pre-processed into a standardized format and the checklists are appropriately customized for local legal and regulatory frameworks. Scaling this system will involve addressing challenges related to the variability in document structure, legal terminology, and the need for more extensive context extraction. Future work should explore these adaptations and consider the integration of additional data sources to further enhance the system's robustness.

\bigskip

\noindent In summary, while the current LLM-based approach demonstrates significant promise in automating administrative regularity controls, it is not yet a complete replacement for human auditors. Nonetheless, it offers a viable and efficient tool that, with further refinement, could substantially improve the auditing processes within public administrations.

\section{Discussion}
When analyzing the It is important to considerIt is well-established in the field that large language models (LLMs) predominantly exhibit English-centric capabilities, leading to significant performance limitations when applied to non-English languages, especially those considered low-resource or requiring domain-specific knowledge like legal texts. Addressing this gap requires targeted multilingual model development and alignment strategies, as standard models often lack the necessary linguistic nuance and specialized data for effective performance in such contexts \cite{qinSurveyMultilingualLarge2025}.

It is well-established within public administration and AI governance studies that while AI systems offer potential efficiencies for public entities, their deployment demands careful scrutiny due to heightened requirements for accountability, transparency, and fairness, alongside prevalent institutional capacity limitations and the inherent risks of bias and opacity in algorithmic decision-making. This context underscores the criticality of assessing novel AI applications, like LLMs for compliance checks, against these established public sector benchmarks and challenges \cite{hickokPublicProcurementArtificial2022}.

Within the field of AI ethics, it is established knowledge that deploying data-driven systems, especially those intended to augment or replace human judgment in sensitive domains like public administration, requires careful consideration of inherent ethical risks. These risks prominently include algorithmic bias stemming from data or design, the challenges of ensuring transparency and explainability in complex models, and the crucial need to define clear frameworks for responsibility and accountability when these systems are used for regulatory decision-making \cite{christoforakiAIEthicsBirds2022}.

Acknowledged within the field of administrative law and artificial intelligence, the integration of machine learning systems for governmental functions, such as administrative regularity control, is recognized as compatible with core legal doctrines like nondelegation, due process, and transparency when appropriately implemented. Experts understand that such algorithmic tools, applied thoughtfully within areas like adjudication and rule enforcement, hold substantial potential to improve the efficiency, accuracy, and consistency of administrative decisions \cite{coglianeseRegulatingRobotAdministrative2017}. 

% Include bibliography only when compiling this subfile independently
\ifSubfilesClassLoaded{
    \bibliographystyle{sapthesis}
    \bibliography{Tesi}
}{}

\end{document}